{
    "table_list": [
        "Layer Type Self-Attention Recurrent Convolutional Self-Attention (restricted) Complexity per Layer O(n2 · d) O(n · d2) O(k · n · d2) O(r · n · d) Sequential Maximum Path Length Operations O(1) O(n) O(1) O(1) O(1) O(n) O(logk(n)) O(n/r)",
        "Model ByteNet [18] Deep-Att + PosUnk [39] GNMT + RL [38] ConvS2S [9] MoE [32] Deep-Att + PosUnk Ensemble [39] GNMT + RL Ensemble [38] ConvS2S Ensemble [9] Transformer (base model) Transformer (big) BLEU EN-DE EN-FR 23.75 24.6 25.16 26.03 26.30 26.36 27.3 28.4 39.2 39.92 40.46 40.56 40.4 41.16 41.29 38.1 41.8 Training Cost (FLOPs) EN-DE EN-FR 2.3 · 1019 9.6 · 1018 2.0 · 1019 1.8 · 1020 7.7 · 1019 1.0 · 1020 1.4 · 1020 1.5 · 1020 1.2 · 1020 8.0 · 1020 1.1 · 1021 1.2 · 1021 3.3 · 1018 2.3 · 1019",
        "base (A) (B) (C) (D) N dmodel 6 512 2 4 8 256 1024 dff 2048 1024 4096 h 8 1 4 16 32 dk 64 512 128 32 16 16 32 32 128 dv 64 512 128 32 16 32 128 Pdrop 0.1 0.0 0.2 ϵls 0.1 0.0 0.2 PPL train steps (dev) 100K 4.92 5.29 5.00 4.91 5.01 5.16 5.01 6.11 5.19 4.88 5.75 4.66 5.12 4.75 5.77 4.95 4.67 5.47 4.92 300K 4.33 BLEU params ×106 (dev) 25.8 65 24.9 25.5 25.8 25.4 25.1 25.4 23.7 25.3 25.5 24.5 26.0 25.4 26.2 24.6 25.5 25.3 25.7 25.7 26.4 58 60 36 50 80 28 168 53 90 (E) big 6 positional embedding instead of sinusoids 1024 4096 16 0.3 213",
        "Parser Training Vinyals & Kaiser el al. (2014) [37] WSJ only, discriminative WSJ only, discriminative WSJ only, discriminative WSJ only, discriminative WSJ only, discriminative semi-supervised semi-supervised semi-supervised semi-supervised semi-supervised multi-task generative Petrov et al. (2006) [29] Zhu et al. (2013) [40] Dyer et al. (2016) [8] Transformer (4 layers) Zhu et al. (2013) [40] Huang & Harper (2009) [14] McClosky et al. (2006) [26] Vinyals & Kaiser el al. (2014) [37] Transformer (4 layers) Luong et al. (2015) [23] Dyer et al. (2016) [8] WSJ 23 F1 88.3 90.4 90.4 91.7 91.3 91.3 91.3 92.1 92.1 92.7 93.0 93.3"
    ],
    "table_summaries": [
        "- **何がまとめられているテーブルなのか:**\n\n    機械学習モデルのレイヤの種類と、その複雑性や最大経路の長さなどの情報をまとめたテーブルです。\n\n\n- **テーブルに記載されているキーワード:**\n\n    Layer Type, Self-Attention, Recurrent Convolutional, Self-Attention (restricted), Complexity per Layer, Sequential Maximum Path Length, Operations\n\n\n- **テーブルから読み取ることができる分析結果:**\n\n    レイヤの種類によって、複雑性や最大経路の長さ、演算量などが異なることがわかります。例えば、Self-Attentionレイヤの複雑性はO(n2 · d)で、Recurrent Convolutionalレイヤの複雑性はO(n · d2)です。また、Self-Attentionレイヤの最大経路の長さはO(1)、Recurrent Convolutionalレイヤの最大経路の長さはO(n)です。このテーブルは、機械学習モデルを設計する際に、どのレイヤをどの順序で組み合わせるかを考える上で参考になります。",
        "- **何がまとめられているテーブルなのか:**\n  - 機械翻訳モデルのBLEUスコアとトレーニングコストの比較表です。\n\n\n- **テーブルに記載されているキーワード:**\n  - BLEUスコア\n  - トレーニングコスト(FLOPs)\n  - EN-DE\n  - EN-FR\n\n\n- **テーブルから読み取ることができる分析結果:**\n  - Transformer (big)モデルは、すべての言語ペアで最高のBLEUスコアを達成しています。\n  - Transformer (base model)モデルは、Transformer (big)モデルに次いで、すべての言語ペアで2番目に高いBLEUスコアを達成しています。\n  - ConvS2S Ensembleモデルは、すべての言語ペアで3番目に高いBLEUスコアを達成しています。\n  - GNMT + RL Ensembleモデルは、すべての言語ペアで4番目に高いBLEUスコアを達成しています。\n  - Deep-Att + PosUnk Ensembleモデルは、すべての言語ペアで5番目に高いBLEUスコアを達成しています。\n  - MoEモデルは、すべての言語ペアで6番目に高いBLEUスコアを達成しています。\n  - ConvS2Sモデルは、すべての言語ペアで7番目に高いBLEUスコアを達成しています。\n  - GNMT + RLモデルは、すべての言語ペアで8番目に高いBLEUスコアを達成しています。\n  - Deep-Att + PosUnkモデルは、すべての言語ペアで9番目に高いBLEUスコアを達成しています。\n  - ByteNetモデルは、すべての言語ペアで10番目に高いBLEUスコアを達成しています。\n  - Transformer (big)モデルは、すべての言語ペアで最も高いトレーニングコストを要しています。\n  - Transformer (base model)モデルは、Transformer (big)モデルに次いで、すべての言語ペアで2番目に高いトレーニングコストを要しています。\n  - ConvS2S Ensembleモデルは、すべての言語ペアで3番目に高いトレーニングコストを要しています。\n  - GNMT + RL Ensembleモデルは、すべての言語ペアで4番目に高いトレーニングコストを要しています。\n  - Deep-Att + PosUnk Ensembleモデルは、すべての言語ペアで5番目に高いトレーニングコストを要しています。\n  - MoEモデルは、すべての言語ペアで6番目に高いトレーニングコストを要しています。\n  - ConvS2Sモデルは、すべての言語ペアで7番目に高いトレーニングコストを要しています。\n  - GNMT + RLモデルは、すべての言語ペアで8番目に高いトレーニングコストを要しています。\n  - Deep-Att + PosUnkモデルは、すべての言語ペアで9番目に高いトレーニングコストを要しています。\n  - ByteNetモデルは、すべての言語ペアで10番目に高いトレーニングコストを要しています。",
        "- 何がまとめられているテーブルなのか\n    機械学習の詳細な設定とその結果をまとめたテーブル。\n\n- テーブルに記載されているキーワード\n    - \"A\"、\"B\"、\"C\"、\"D\"、\"E\"：モデルの設定を示すアルファベット。\n    - \"dmodel\"：モデルの次元。\n    - \"dff\"：Feed Forward Networkの次元。\n    - \"h\"：モデルのヘッド数。\n    - \"dk\"：注意メカニズムの次元。\n    - \"dv\"：注意メカニズムの価値の次元。\n    - \"Pdrop\"：ドロップアウトの確率。\n    - \"ϵls\"：学習率の減衰率。\n    - \"PPL\"：パープレキシティ。\n    - \"train steps\"：訓練のステップ数。\n    - \"(dev)\"：開発セットでの結果。\n    - \"BLEU\"：機械翻訳の評価指標であるBLEUスコア。\n    - \"params\"：モデルのパラメータ数。\n\n- テーブルから読み取ることができる分析結果\n    - モデルの設定によって、PPLやBLEUスコアが異なることがわかる。\n    - 一般的に、モデルの次元やヘッド数が多いほど、PPLやBLEUスコアは良くなる傾向にある。\n    - ドロップアウトの確率や学習率の減衰率を大きくすると、PPLやBLEUスコアが悪くなる傾向にある。\n    - 訓練のステップ数を多くすると、PPLやBLEUスコアは良くなる傾向にある。",
        "- **何がまとめられているテーブルなのか:**\n\n   自然言語処理の論文における構文解析器のトレーニングに関するテーブル。\n\n- **テーブルに記載されているキーワード:**\n\n   - 構文解析器\n   - 自然言語処理\n   - 論文\n   - F1\n\n- **テーブルから読み取ることができる分析結果:**\n\n   - Vinyals & Kaiser el al. (2014) [37] の論文で提案された構文解析器は、WSJデータセットでのF1スコアが91.7で、他の論文の構文解析器よりも高い性能を示した。\n   - Luong et al. (2015) [23] の論文で提案された構文解析器は、WSJデータセットでのF1スコアが93.0で、Vinyals & Kaiser el al. (2014) [37] の論文で提案された構文解析器よりも高い性能を示した。\n   - Dyer et al. (2016) [8] の論文で提案された構文解析器は、WSJデータセットでのF1スコアが93.3で、Luong et al. (2015) [23] の論文で提案された構文解析器よりも高い性能を示した。"
    ]
}